{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726},{"sourceId":7319098,"sourceType":"datasetVersion","datasetId":4247396}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n# GPU memory growth configuration\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T09:33:24.753035Z","iopub.execute_input":"2024-01-03T09:33:24.753435Z","iopub.status.idle":"2024-01-03T09:33:24.769833Z","shell.execute_reply.started":"2024-01-03T09:33:24.753405Z","shell.execute_reply":"2024-01-03T09:33:24.768319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dataset details**\n\nThe dataset contains two classes - REAL and FAKE.\n\nFor REAL, we collected the images from Krizhevsky & Hinton's CIFAR-10 dataset\n\nFor the FAKE images, we generated the equivalent of CIFAR-10 with Stable Diffusion version 1.4\n\nThere are 100,000 images for training (50k per class) and 20,000 for testing (10k per class)","metadata":{}},{"cell_type":"markdown","source":"# Load the dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport cv2\nfrom keras.utils import to_categorical\n# Define paths to the train and test directories\ntrain_dir_real = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/REAL'\ntrain_dir_fake = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE'\ntest_dir_real = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/REAL'\ntest_dir_fake = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/FAKE'\n\n# Function to load images and labels\ndef load_images_and_labels(directory, label):\n    images = []\n    labels = []\n    for filename in os.listdir(directory):\n        img_path = os.path.join(directory, filename)\n        img = cv2.imread(img_path)\n        img = cv2.resize(img, (32, 32)) \n        images.append(img)\n        labels.append(label)\n    return images, labels\n\n# Load REAL train images and labels\nreal_train_images, real_train_labels = load_images_and_labels(train_dir_real, label=0)\n\n# Load FAKE train images and labels\nfake_train_images, fake_train_labels = load_images_and_labels(train_dir_fake, label=1)\n\n# Load REAL test images and labels\nreal_test_images, real_test_labels = load_images_and_labels(test_dir_real, label=0)\n\n# Load FAKE test images and labels\nfake_test_images, fake_test_labels = load_images_and_labels(test_dir_fake, label=1)\n\n# Concatenate REAL and FAKE train/test data and labels\nX_train = np.concatenate((real_train_images, fake_train_images), axis=0)\ny_train = np.concatenate((real_train_labels, fake_train_labels), axis=0)\nX_test = np.concatenate((real_test_images, fake_test_images), axis=0)\ny_test = np.concatenate((real_test_labels, fake_test_labels), axis=0)\n\n# Convert labels to one-hot encoding\ny_train = np.eye(2)[y_train]\ny_test = np.eye(2)[y_test]\n\n# Normalize image data\nX_train = X_train.astype('float32') / 255.0\nX_test = X_test.astype('float32') / 255.0","metadata":{"execution":{"iopub.status.busy":"2024-01-03T09:33:28.465893Z","iopub.execute_input":"2024-01-03T09:33:28.466699Z","iopub.status.idle":"2024-01-03T09:47:57.664144Z","shell.execute_reply.started":"2024-01-03T09:33:28.466659Z","shell.execute_reply":"2024-01-03T09:47:57.662960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. test for the data to work correctly","metadata":{}},{"cell_type":"code","source":"print(\"Total number of REAL images in y_train:\", np.sum(y_train[:, 0]))\nprint(\"Total number of FAKE images in y_train:\", np.sum(y_train[:, 1]))\n\nprint(\"Number of REAL images in the first 50000 samples:\", np.sum(y_train[:50000, 0]))\nprint(\"Number of FAKE images in the first 50000 samples:\", np.sum(y_train[:50000, 1]))\n\nprint(\"Number of REAL images in the second 50000 samples:\", np.sum(y_train[50000:, 0]))\nprint(\"Number of FAKE images in the second 50000 samples:\", np.sum(y_train[50000:, 1]))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:53:05.050339Z","iopub.execute_input":"2024-01-03T16:53:05.050910Z","iopub.status.idle":"2024-01-03T16:53:05.064426Z","shell.execute_reply.started":"2024-01-03T16:53:05.050870Z","shell.execute_reply":"2024-01-03T16:53:05.062514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total number of REAL images in y_test:\", np.sum(y_test[:, 0]))\nprint(\"Total number of FAKE images in y_test:\", np.sum(y_test[:, 1]))\n\nprint(\"Number of REAL images in the first 10000 samples:\", np.sum(y_test[:10000, 0]))\nprint(\"Number of FAKE images in the first 10000 samples:\", np.sum(y_test[:10000, 1]))\n\nprint(\"Number of REAL images in the second 10000 samples:\", np.sum(y_test[10000:, 0]))\nprint(\"Number of FAKE images in the second 10000 samples:\", np.sum(y_test[10000:, 1]))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:53:06.310183Z","iopub.execute_input":"2024-01-03T16:53:06.310650Z","iopub.status.idle":"2024-01-03T16:53:06.324103Z","shell.execute_reply.started":"2024-01-03T16:53:06.310617Z","shell.execute_reply":"2024-01-03T16:53:06.322029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*** Guaranteeing balance between real and fake images in each batch for training an image classification model**","metadata":{}},{"cell_type":"code","source":"# Shuffle the order of REAL and FAKE train data\nshuffled_indices_train = np.arange(X_train.shape[0])\nnp.random.shuffle(shuffled_indices_train)\n\n# Use the same set of shuffled indices for both images and labels\nX_train = X_train[shuffled_indices_train]\ny_train = y_train[shuffled_indices_train]\n\n# Shuffle the order of REAL and FAKE test data\nshuffled_indices_test = np.arange(X_test.shape[0])\nnp.random.shuffle(shuffled_indices_test)\n\n# Use the same set of shuffled indices for both images and labels\nX_test = X_test[shuffled_indices_test]\ny_test = y_test[shuffled_indices_test]","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:54:03.314599Z","iopub.execute_input":"2024-01-03T16:54:03.315066Z","iopub.status.idle":"2024-01-03T16:54:04.067725Z","shell.execute_reply.started":"2024-01-03T16:54:03.315033Z","shell.execute_reply":"2024-01-03T16:54:04.066683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. test for the data to work correctly","metadata":{}},{"cell_type":"code","source":"# Print the class distribution in y_train\nprint(\"Class distribution in y_train:\", np.sum(y_train, axis=0))\n\n# Print the class distribution in y_test\nprint(\"Class distribution in y_test:\", np.sum(y_test, axis=0))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:54:05.085604Z","iopub.execute_input":"2024-01-03T16:54:05.086388Z","iopub.status.idle":"2024-01-03T16:54:05.096273Z","shell.execute_reply.started":"2024-01-03T16:54:05.086349Z","shell.execute_reply":"2024-01-03T16:54:05.095197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total number of REAL images in y_test:\", np.sum(y_test[:, 0]))\nprint(\"Total number of FAKE images in y_test:\", np.sum(y_test[:, 1]))\n\nprint(\"Number of REAL images in the first 10000 samples:\", np.sum(y_test[:10000, 0]))\nprint(\"Number of FAKE images in the first 10000 samples:\", np.sum(y_test[:10000, 1]))\n\nprint(\"Number of REAL images in the second 10000 samples:\", np.sum(y_test[10000:, 0]))\nprint(\"Number of FAKE images in the second 10000 samples:\", np.sum(y_test[10000:, 1]))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:58:30.170985Z","iopub.execute_input":"2024-01-03T16:58:30.172438Z","iopub.status.idle":"2024-01-03T16:58:30.182203Z","shell.execute_reply.started":"2024-01-03T16:58:30.172371Z","shell.execute_reply":"2024-01-03T16:58:30.180797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total number of REAL images in y_train:\", np.sum(y_train[:, 0]))\nprint(\"Total number of FAKE images in y_train:\", np.sum(y_train[:, 1]))\n\nprint(\"Number of REAL images in the first 50000 samples:\", np.sum(y_train[:50000, 0]))\nprint(\"Number of FAKE images in the first 50000 samples:\", np.sum(y_train[:50000, 1]))\n\nprint(\"Number of REAL images in the second 50000 samples:\", np.sum(y_train[50000:, 0]))\nprint(\"Number of FAKE images in the second 50000 samples:\", np.sum(y_train[50000:, 1]))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:58:36.424281Z","iopub.execute_input":"2024-01-03T16:58:36.425425Z","iopub.status.idle":"2024-01-03T16:58:36.436631Z","shell.execute_reply.started":"2024-01-03T16:58:36.425362Z","shell.execute_reply":"2024-01-03T16:58:36.435665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build the CNN model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\n\nmodel.add(Dropout(0.2))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(Dense(2, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:58:43.425371Z","iopub.execute_input":"2024-01-03T16:58:43.425896Z","iopub.status.idle":"2024-01-03T16:58:43.733210Z","shell.execute_reply.started":"2024-01-03T16:58:43.425857Z","shell.execute_reply":"2024-01-03T16:58:43.731711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:58:43.736255Z","iopub.execute_input":"2024-01-03T16:58:43.736694Z","iopub.status.idle":"2024-01-03T16:58:43.757540Z","shell.execute_reply.started":"2024-01-03T16:58:43.736659Z","shell.execute_reply":"2024-01-03T16:58:43.756133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:58:44.933770Z","iopub.execute_input":"2024-01-03T16:58:44.934151Z","iopub.status.idle":"2024-01-03T16:58:45.009172Z","shell.execute_reply.started":"2024-01-03T16:58:44.934122Z","shell.execute_reply":"2024-01-03T16:58:45.007870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=100)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T14:14:10.376327Z","iopub.execute_input":"2024-01-03T14:14:10.376874Z","iopub.status.idle":"2024-01-03T15:52:29.902187Z","shell.execute_reply.started":"2024-01-03T14:14:10.376827Z","shell.execute_reply":"2024-01-03T15:52:29.897456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npd.DataFrame(history.history).plot()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:53:50.024665Z","iopub.execute_input":"2024-01-03T15:53:50.025464Z","iopub.status.idle":"2024-01-03T15:53:50.549195Z","shell.execute_reply.started":"2024-01-03T15:53:50.025414Z","shell.execute_reply":"2024-01-03T15:53:50.547529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Predictions on test set\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true_classes = np.argmax(y_test, axis=1)\n\n# Calculate confusion matrix\ncm = confusion_matrix(y_true_classes, y_pred_classes, labels=[0, 1])\n\n# Display confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"REAL\", \"FAKE\"])\ndisp.plot(cmap='viridis', values_format='d')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:54:10.165262Z","iopub.execute_input":"2024-01-03T15:54:10.166267Z","iopub.status.idle":"2024-01-03T15:54:31.861083Z","shell.execute_reply.started":"2024-01-03T15:54:10.166205Z","shell.execute_reply":"2024-01-03T15:54:31.859451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Classification report\nprint(classification_report(y_true_classes, y_pred_classes, target_names=[\"REAL\", \"FAKE\"]))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:55:12.878964Z","iopub.execute_input":"2024-01-03T15:55:12.879470Z","iopub.status.idle":"2024-01-03T15:55:12.940528Z","shell.execute_reply.started":"2024-01-03T15:55:12.879429Z","shell.execute_reply":"2024-01-03T15:55:12.938665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [\"REAL\", \"FAKE\"]\n\nfig, axes = plt.subplots(ncols=7, nrows=3, sharex=False,\n    sharey=True, figsize=(17, 8))\nindex = 0\nfor i in range(3):\n    for j in range(7):\n        actual_label = labels[np.argmax(y_test[index])]\n        predicted_label = labels[np.argmax(predictions[index])]\n        axes[i, j].set_title(f'actual: {actual_label}\\npredicted: {predicted_label}')\n        axes[i, j].imshow(X_test[index], cmap='gray')\n        axes[i, j].get_xaxis().set_visible(False)\n        axes[i, j].get_yaxis().set_visible(False)\n        index += 1\n\n# Add debug information\nprint(\"Sample Order:\")\nprint(np.argmax(y_test[20:50], axis=1))\nprint(\"Predictions Order:\")\nprint(np.argmax(predictions[20:50], axis=1))\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T19:13:55.877001Z","iopub.execute_input":"2024-01-03T19:13:55.877541Z","iopub.status.idle":"2024-01-03T19:13:56.832041Z","shell.execute_reply.started":"2024-01-03T19:13:55.877505Z","shell.execute_reply":"2024-01-03T19:13:56.830866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(X_test)\nfor i in range(10):\n    actual_label = labels[np.argmax(y_test[i])]\n    predicted_label = labels[np.argmax(predictions[i])]\n    print(f'Sample {i + 1} - Actual: {actual_label}, Predicted: {predicted_label}')","metadata":{"execution":{"iopub.status.busy":"2024-01-03T17:02:53.060868Z","iopub.execute_input":"2024-01-03T17:02:53.061437Z","iopub.status.idle":"2024-01-03T17:03:16.072385Z","shell.execute_reply.started":"2024-01-03T17:02:53.061396Z","shell.execute_reply":"2024-01-03T17:03:16.070844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}